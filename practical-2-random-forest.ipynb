{
 "metadata": {
  "name": "",
  "signature": "sha256:5054baaa46b8b91074e88954a7c5678168f1f62bf9805562a5b7d446b167ef51"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "from collections import Counter\n",
      "try:\n",
      "    import xml.etree.cElementTree as ET\n",
      "except ImportError:\n",
      "    import xml.etree.ElementTree as ET\n",
      "import numpy as np\n",
      "from scipy import sparse\n",
      "from sklearn import cross_validation\n",
      "from sklearn.ensemble import RandomForestClassifier \n",
      "\n",
      "import util"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "all_sys = Counter()\n",
      "\n",
      "for datafile in os.listdir(\"train\"):\n",
      "    # extract id and true class (if available) from filename\n",
      "    id_str,clazz = datafile.split('.')[:2]\n",
      "#     ids.append(id_str)\n",
      "    # add target class if this is training data\n",
      "#     try:\n",
      "#         classes.append(util.malware_classes.index(clazz))\n",
      "#     except ValueError:\n",
      "        # we should only fail to find the label in our list of malware classes\n",
      "        # if this is test data, which always has an \"X\" label\n",
      "#         assert clazz == \"X\"\n",
      "#         classes.append(-1)\n",
      "#     rowfd = {}\n",
      "    # parse file as an xml document\n",
      "    tree = ET.parse(os.path.join('train',datafile))\n",
      "    # accumulate features\n",
      "    get_distinct_calls(tree, all_sys)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extract_feats(ffs, direc=\"train\", global_feat_dict=None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      ffs are a list of feature-functions.\n",
      "      direc is a directory containing xml files (expected to be train or test).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "\n",
      "    returns: \n",
      "      a sparse design matrix, a dict mapping features to column-numbers,\n",
      "      a vector of target classes, and a list of system-call-history ids in order \n",
      "      of their rows in the design matrix.\n",
      "      \n",
      "      Note: the vector of target classes returned will contain the true indices of the\n",
      "      target classes on the training data, but will contain only -1's on the test\n",
      "      data\n",
      "    \"\"\"\n",
      "    fds = [] # list of feature dicts\n",
      "    classes = []\n",
      "    ids = [] \n",
      "    for datafile in os.listdir(direc):\n",
      "        # extract id and true class (if available) from filename\n",
      "        id_str,clazz = datafile.split('.')[:2]\n",
      "        ids.append(id_str)\n",
      "        # add target class if this is training data\n",
      "        try:\n",
      "            classes.append(util.malware_classes.index(clazz))\n",
      "        except ValueError:\n",
      "            # we should only fail to find the label in our list of malware classes\n",
      "            # if this is test data, which always has an \"X\" label\n",
      "            assert clazz == \"X\"\n",
      "            classes.append(-1)\n",
      "        rowfd = {}\n",
      "        # parse file as an xml document\n",
      "        tree = ET.parse(os.path.join(direc,datafile))\n",
      "        # accumulate features\n",
      "        [rowfd.update(ff(tree)) for ff in ffs]\n",
      "        fds.append(rowfd)\n",
      "        \n",
      "    X,feat_dict = make_design_mat(fds,global_feat_dict)\n",
      "    return X, feat_dict, np.array(classes), ids\n",
      "\n",
      "\n",
      "def make_design_mat(fds, global_feat_dict=None):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      fds is a list of feature dicts (one for each row).\n",
      "      global_feat_dict is a dictionary mapping feature_names to column-numbers; it\n",
      "      should only be provided when extracting features from test data, so that \n",
      "      the columns of the test matrix align correctly.\n",
      "       \n",
      "    returns: \n",
      "        a sparse NxD design matrix, where N == len(fds) and D is the number of\n",
      "        the union of features defined in any of the fds \n",
      "    \"\"\"\n",
      "    if global_feat_dict is None:\n",
      "        all_feats = set()\n",
      "        [all_feats.update(fd.keys()) for fd in fds]\n",
      "        feat_dict = dict([(feat, i) for i, feat in enumerate(sorted(all_feats))])\n",
      "    else:\n",
      "        feat_dict = global_feat_dict\n",
      "        \n",
      "    cols = []\n",
      "    rows = []\n",
      "    data = []        \n",
      "    for i in xrange(len(fds)):\n",
      "        temp_cols = []\n",
      "        temp_data = []\n",
      "        for feat,val in fds[i].iteritems():\n",
      "            try:\n",
      "                # update temp_cols iff update temp_data\n",
      "                temp_cols.append(feat_dict[feat])\n",
      "                temp_data.append(val)\n",
      "            except KeyError as ex:\n",
      "                if global_feat_dict is not None:\n",
      "                    pass  # new feature in test data; nbd\n",
      "                else:\n",
      "                    raise ex\n",
      "\n",
      "        # all fd's features in the same row\n",
      "        k = len(temp_cols)\n",
      "        cols.extend(temp_cols)\n",
      "        data.extend(temp_data)\n",
      "        rows.extend([i]*k)\n",
      "\n",
      "    assert len(cols) == len(rows) and len(rows) == len(data)\n",
      "   \n",
      "\n",
      "    X = sparse.csr_matrix((np.array(data),\n",
      "                   (np.array(rows), np.array(cols))),\n",
      "                   shape=(len(fds), len(feat_dict)))\n",
      "    return X, feat_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 208
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def first_last_system_call_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'first_call-x' to 1 if x was the first system call\n",
      "      made, and 'last_call-y' to 1 if y was the last system call made. \n",
      "      (in other words, it returns a dictionary indicating what the first and \n",
      "      last system calls made by an executable were.)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    first = True # is this the first system call\n",
      "    last_call = None # keep track of last call we've seen\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if first:\n",
      "                c[\"first_call-\"+el.tag] = 1\n",
      "                first = False\n",
      "            last_call = el.tag  # update last call seen\n",
      "            \n",
      "    # finally, mark last call seen\n",
      "    c[\"last_call-\"+last_call] = 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def system_call_count_feats(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            c['num_system_calls'] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def dump_line_count(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if el.tag == \"dump_line\":\n",
      "                c['dump_line'] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 170
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# def destroy_window_count(tree):\n",
      "#     \"\"\"\n",
      "#     arguments:\n",
      "#       tree is an xml.etree.ElementTree object\n",
      "#     returns:\n",
      "#       a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "#       made by an executable (summed over all processes)\n",
      "#     \"\"\"\n",
      "#     c = Counter()\n",
      "#     in_all_section = False\n",
      "#     for el in tree.iter():\n",
      "#         # ignore everything outside the \"all_section\" element\n",
      "#         if el.tag == \"all_section\" and not in_all_section:\n",
      "#             in_all_section = True\n",
      "#         elif el.tag == \"all_section\" and in_all_section:\n",
      "#             in_all_section = False\n",
      "#         elif in_all_section:\n",
      "#             if el.tag == \"destroy_window\":\n",
      "#                 c['destroy_window'] += 1\n",
      "#     return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 172
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def impersonate_user_count(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if el.tag == \"impersonate_user\":\n",
      "                c['impersonate_user'] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 173
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def total_indiv_count(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = all_sys\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if el.tag in c:\n",
      "                c[el.tag] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_distinct_calls(tree, all_sys):\n",
      "    \n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if not el.tag in all_sys:\n",
      "                all_sys[el.tag]=0\n",
      "   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def destroy_window_count(tree):\n",
      "    \"\"\"\n",
      "    arguments:\n",
      "      tree is an xml.etree.ElementTree object\n",
      "    returns:\n",
      "      a dictionary mapping 'num_system_calls' to the number of system_calls\n",
      "      made by an executable (summed over all processes)\n",
      "    \"\"\"\n",
      "    c = Counter()\n",
      "    in_all_section = False\n",
      "    for el in tree.iter():\n",
      "        # ignore everything outside the \"all_section\" element\n",
      "        if el.tag == \"all_section\" and not in_all_section:\n",
      "            in_all_section = True\n",
      "        elif el.tag == \"all_section\" and in_all_section:\n",
      "            in_all_section = False\n",
      "        elif in_all_section:\n",
      "            if el.tag == \"destroy_window\":\n",
      "                c['destroy_window'] += 1\n",
      "    return c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 171
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_all_sys = Counter()\n",
      "ind = 0\n",
      "for i in all_sys.keys():\n",
      "    new_all_sys[i] = ind\n",
      "    ind += 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 230
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# WORKFLOW\n",
      "train_dir = \"train\"\n",
      "test_dir = \"test\"\n",
      "outputfile = \"mypredictions_randomforest.csv\"  # feel free to change this or take it as an argument"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO put the names of the feature functions you've defined above in this list\n",
      "ffs = [first_last_system_call_feats, system_call_count_feats, dump_line_count, impersonate_user_count, total_indiv_count]\n",
      "\n",
      "# extract features\n",
      "print \"extracting training features...\"\n",
      "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
      "print \"done extracting training features\"\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "extracting training features...\n",
        "done extracting training features"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# cross validation\n",
      "X1_train, Y1_test, X1_t, Y1_t = cross_validation.train_test_split(X_train, t_train, test_size=0.4, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO train here, and learn your classification parameters\n",
      "forest = RandomForestClassifier(n_estimators = 100)\n",
      "print \"learning...\"\n",
      "forest = forest.fit(X1_train.toarray(), X1_t)\n",
      "# learned_W = np.random.random((len(global_feat_dict),len(util.malware_classes)))\n",
      "print \"done learning\"\n",
      "print\n",
      "forest.score(Y1_test.toarray(), Y1_t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "learning...\n",
        "done learning"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 228,
       "text": [
        "0.62024291497975703"
       ]
      }
     ],
     "prompt_number": 228
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get rid of training data and load test data\n",
      "# del X_train\n",
      "# del t_train\n",
      "# del train_ids\n",
      "print \"extracting test features...\"\n",
      "X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
      "print \"done extracting test features\"\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "extracting test features...\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-182-53e18aaad1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# del train_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"extracting test features...\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_ignore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_feat_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobal_feat_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"done extracting test features\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-48-1b26998e7705>\u001b[0m in \u001b[0;36mextract_feats\u001b[0;34m(ffs, direc, global_feat_dict)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# accumulate features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mrowfd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mffs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mfds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-172-ac5bc87b7441>\u001b[0m in \u001b[0;36mdestroy_window_count\u001b[0;34m(tree)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0min_all_section\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# ignore everything outside the \"all_section\" element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"all_section\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_all_section\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36miter\u001b[0;34m(node, tag)\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36miter\u001b[0;34m(node, tag)\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36miter\u001b[0;34m(node, tag)\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36miter\u001b[0;34m(node, tag)\u001b[0m\n",
        "\u001b[0;32m<string>\u001b[0m in \u001b[0;36miter\u001b[0;34m(node, tag)\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO make predictions on text data and write them out\n",
      "print \"making predictions...\"\n",
      "preds = forest.predict(X_test.toarray())\n",
      "print \"done making predictions\"\n",
      "print\n",
      "\n",
      "print \"writing predictions...\"\n",
      "util.write_predictions(preds, test_ids, outputfile)\n",
      "print \"done!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "making predictions...\n",
        "done making predictions"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "writing predictions...\n",
        "done!\n"
       ]
      }
     ],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}